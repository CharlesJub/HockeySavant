{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from selectolax.parser import HTMLParser\n",
    "from time import sleep\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(player_text):\n",
    "    \"\"\"\n",
    "    Clean and format a player's name extracted from the draft table.\n",
    "\n",
    "    Parameters:\n",
    "    player_text (str): The text representing a player's name, which may include roles like (D), (F), or (G).\n",
    "\n",
    "    Returns:\n",
    "    str: The cleaned and formatted player name without role indicators.\n",
    "\n",
    "    This function takes a player's name as input, which may include roles such as (D) for defense, (F) for forward, or (G) for goalie.\n",
    "    It removes these role indicators, trims any leading or trailing white spaces, and returns the cleaned and formatted player name.\n",
    "\n",
    "    Example:\n",
    "    original_name = \"John Smith (F)\"\n",
    "    cleaned_name = clean_name(original_name)\n",
    "    # cleaned_name will be \"John Smith\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the cleaned_name with the original text\n",
    "    cleaned_name = player_text.text().strip().split(' (')[0]\n",
    "    \n",
    "    # Iterate through roles_to_remove and remove them from the name\n",
    "    \n",
    "    \n",
    "    return cleaned_name\n",
    "\n",
    "def scrape_ep_draft(draft_year):\n",
    "    \"\"\"\n",
    "    Scrape data from Elite Prospects NHL Entry Draft page for a given draft year.\n",
    "\n",
    "    Parameters:\n",
    "    draft_year (int or str): The year of the NHL Entry Draft to scrape data for.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame containing draft data including pick number, team, player name, and links.\n",
    "\n",
    "    This function sends an HTTP GET request to the Elite Prospects website for the specified draft year.\n",
    "    It then extracts data from the draft table, including pick numbers, team names, player names, and links.\n",
    "    The data is organized into a DataFrame and returned for further analysis.\n",
    "\n",
    "    Example:\n",
    "    def clean_name(name):\n",
    "        # Implement your cleaning logic here\n",
    "        return cleaned_name\n",
    "    \"\"\"\n",
    "    # Construct the URL for Elite Prospects NHL Entry Draft page for the given 'draft_year'\n",
    "    draft_url = f\"https://www.eliteprospects.com/draft/nhl-entry-draft/{draft_year}\"\n",
    "    \n",
    "    # Send an HTTP GET request to the URL\n",
    "    resp = requests.get(draft_url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if resp.status_code == 200:\n",
    "        # Parse the HTML content of the response\n",
    "        html = HTMLParser(resp.text)\n",
    "        \n",
    "        # Extract the draft table element\n",
    "        draft_table = html.css_first('.players.table')\n",
    "        \n",
    "        # Extract data from different columns of the draft table\n",
    "        pick_number = [clean_name(overall_text) for overall_text in draft_table.css('td.overall')]\n",
    "        pick_team = [clean_name(team_text) for team_text in draft_table.css('td.team')]\n",
    "        pick_team_link = [team_node.css_first('a').attributes['href'] for team_node in draft_table.css('td.team')]\n",
    "        player_name = [clean_name(player_text) for player_text in draft_table.css('td.player')]\n",
    "        player_link = [player_node.css_first('a').attributes['href'] for player_node in draft_table.css('td.player')]\n",
    "        \n",
    "        # Create a DataFrame to store the extracted data\n",
    "        data = pd.DataFrame({'draft_year': draft_year,\n",
    "                             'pick_number': pick_number,\n",
    "                             'pick_team': pick_team,\n",
    "                             'pick_team_link': pick_team_link,\n",
    "                             'player_name': player_name,\n",
    "                             'player_link': player_link})\n",
    "        \n",
    "        # Return the DataFrame\n",
    "        return data\n",
    "    else:\n",
    "        # If the request was not successful, print the status code\n",
    "        print(f\"Got status code: {resp.status_code}\")\n",
    "\n",
    "def get_players_by_draft_year(draft_year):\n",
    "    \"\"\"\n",
    "    Scrape player data from Elite Prospects by draft year.\n",
    "\n",
    "    Args:\n",
    "        draft_year (int): The year of the NHL draft to retrieve player data for.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing player names and their corresponding links.\n",
    "    \"\"\"\n",
    "    draft_year_url = f\"https://www.eliteprospects.com/search/player?draft={draft_year}\"\n",
    "\n",
    "    player_names_full_draft_class = []\n",
    "    player_links_full_draft_class = []\n",
    "\n",
    "    # Make an HTTP request to the Elite Prospects website\n",
    "    resp = requests.get(draft_year_url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if resp.status_code == 200:\n",
    "        # Parse the HTML response\n",
    "        html = HTMLParser(resp.text)\n",
    "        \n",
    "        # Extract information about the number of pages in the draft class\n",
    "        last_page_link = html.css_first('div.table-pagination').css('span')[1].css_first('a').attributes['href']\n",
    "        last_page = int(last_page_link[last_page_link.find('page=')+5:])\n",
    "        \n",
    "        # Extract player names and links from the first page\n",
    "        table = html.css_first(\".table.players\")\n",
    "        player_names = [clean_name(name) for name in table.css('td.name')]\n",
    "        player_links = [name.css_first('a').attributes['href'] for name in table.css('td.name')]\n",
    "        player_names_full_draft_class.extend(player_names)\n",
    "        player_links_full_draft_class.extend(player_links)\n",
    "\n",
    "        # Loop through the remaining pages using tqdm for a progress bar\n",
    "        for page_number in tqdm(range(2, last_page + 1), desc=f\"Scraping {draft_year} draft eligibles\"):\n",
    "            page_ending = f\"&page={page_number}\"\n",
    "            resp = requests.get(draft_year_url + page_ending)\n",
    "\n",
    "            # Handle 403 errors by waiting and retrying\n",
    "            while resp.status_code == 403:\n",
    "                print(f\"Waiting 100 seconds to resend request for page {page_number}\")\n",
    "                sleep(100)\n",
    "                resp = requests.get(draft_year_url + page_ending)\n",
    "\n",
    "            if resp.status_code == 200:\n",
    "                # Parse and extract data from the current page\n",
    "                html = HTMLParser(resp.text)\n",
    "                table = html.css_first(\".table.players\")\n",
    "                player_names = [clean_name(name) for name in table.css('td.name')]\n",
    "                player_links = [name.css_first('a').attributes['href'] for name in table.css('td.name')]\n",
    "                player_names_full_draft_class.extend(player_names)\n",
    "                player_links_full_draft_class.extend(player_links)\n",
    "            else:\n",
    "                print(f\"Request Failed. Status Code: {resp.status_code}. Page: {page_number}\")\n",
    "\n",
    "        # Create a DataFrame from the collected data\n",
    "        return pd.DataFrame({'player_name': player_names_full_draft_class,\n",
    "                             'player_link': player_links_full_draft_class})\n",
    "    else:\n",
    "        print(f\"Request Failed. Status Code: {resp.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping 2023-2024 draft eligibles: 100%|██████████| 16/16 [00:12<00:00,  1.30it/s]\n"
     ]
    }
   ],
   "source": [
    "season = \"2023-2024\"\n",
    "league = \"NCAA\"\n",
    "def scrape_ep_league(season, league):\n",
    "    league_url = f\"https://www.eliteprospects.com/league/{league}/stats/{season}\"\n",
    "\n",
    "    player_names_full_league = []\n",
    "    player_links_full_league = []\n",
    "\n",
    "# Make an HTTP request to the Elite Prospects website\n",
    "    resp = requests.get(league_url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "    if resp.status_code == 200:\n",
    "    # Parse the HTML response\n",
    "        html = HTMLParser(resp.text)\n",
    "    \n",
    "    # Extract information about the number of pages in the draft class\n",
    "        last_page_link = html.css_first('div.table-pagination').css('span')[1].css_first('a').attributes['href']\n",
    "        last_page = int(last_page_link[last_page_link.find('page=')+5:])\n",
    "    \n",
    "    # Extract player names and links from the first page\n",
    "        table = html.css_first(\".table.player-stats\")\n",
    "        player_names = [clean_name(name) for name in table.css('td.player')]\n",
    "        player_links = [name.css_first('a').attributes['href'] if name.css_first('a') != None else None for name in table.css('td.player')]\n",
    "        player_names_full_league.extend(player_names)\n",
    "        player_links_full_league.extend(player_links)\n",
    "\n",
    "    # Loop through the remaining pages using tqdm for a progress bar\n",
    "        for page_number in tqdm(range(2, last_page + 1), desc=f\"Scraping {league}, {season} players\"):\n",
    "            page_ending = f\"&page={page_number}\"\n",
    "            resp = requests.get(league_url + page_ending)\n",
    "\n",
    "        # Handle 403 errors by waiting and retrying\n",
    "            while resp.status_code == 403:\n",
    "                print(f\"Waiting 100 seconds to resend request for page {page_number}\")\n",
    "                sleep(100)\n",
    "                resp = requests.get(league_url + page_ending)\n",
    "\n",
    "            if resp.status_code == 200:\n",
    "            # Parse and extract data from the current page\n",
    "                html = HTMLParser(resp.text)\n",
    "                table = html.css_first(\".table.player-stats\")\n",
    "                player_names = [clean_name(name) for name in table.css('td.player')]\n",
    "                player_links = [name.css_first('a').attributes['href'] if name.css_first('a') != None else None for name in table.css('td.player')]\n",
    "                player_names_full_league.extend(player_names)\n",
    "                player_links_full_league.extend(player_links)\n",
    "            else:\n",
    "                print(f\"Request Failed. Status Code: {resp.status_code}. Page: {page_number}\")\n",
    "        # Create data frame for all full league data\n",
    "        league_df = pd.DataFrame({'player_name': player_names_full_league,\n",
    "                                  'player_link': player_links_full_league})\n",
    "        # Return data frame of \n",
    "        return league_df[league_df['player_link' != None]]\n",
    "    \n",
    "    else:\n",
    "        print(f\"Request Failed. Status Code: {resp.status_code}\")\n",
    "\n",
    "scrape_ep_league(season, league)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
